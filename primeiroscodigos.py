# -*- coding: utf-8 -*-
"""primeirosCodigos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WaMQo_2sfzeQZ9F_3LofkMNrjFxqH5Ff
"""

#from google.colab import drive
#drive.mount('/content/drive')

#TensorFlow e Keras
import tensorflow as tf
from tensorflow import keras

#Bibliotecas auxiliaresmuffin
import numpy as np
from matplotlib import pyplot as plt
import glob, os
import re
import pickle

#Pillow
import PIL
from PIL import Image

def jpeg_to_8_bit_greyscale(path, maxsize):

        img = Image.open(path)#.convert('L')   # convert image to 8-bit grayscale

        # Make aspect ratio as 1:1, by applying image crop.

    # Please note, croping works for this data set, but in general one

    # needs to locate the subject and then crop or scale accordingly.

        WIDTH, HEIGHT = img.size

        if WIDTH != HEIGHT:

                m_min_d = min(WIDTH, HEIGHT)

                img = img.crop((0, 0, m_min_d, m_min_d))

        # Scale the image to the requested maxsize by Anti-alias sampling.

        img.thumbnail(maxsize, PIL.Image.ANTIALIAS)

        return np.asarray(img)

def load_image_dataset(path_dir, maxsize):

        images = []

        labels = []

        os.chdir(path_dir)

        for file in glob.glob("*.jpg"):

                img = jpeg_to_8_bit_greyscale(file, maxsize)

                if re.match('healthy*.', file):

                        images.append(img)

                        labels.append(0)

                elif re.match('infected*.', file):

                        images.append(img)

                        labels.append(1)

        return (np.asarray(images), np.asarray(labels))

maxsize = 512, 512

(train_images, train_labels) = load_image_dataset('datasets/dataset', maxsize)

(test_images, test_labels) = load_image_dataset('datasets/dataset2', maxsize)

class_names = ['saudavel', 'doente']

train_images.shape

print(train_labels)

test_images.shape

print(test_labels)

def display_images(images, labels):

        plt.figure(figsize=(10,10))

        grid_size = min(25, len(images))

        for i in range(grid_size):

                plt.subplot(5, 5, i+1)

                plt.xticks([])

                plt.yticks([])

                plt.grid(False)

                plt.imshow(images[i], cmap=plt.cm.binary)

                plt.xlabel(class_names[labels[i]])

display_images(train_images, train_labels)
plt.show()

train_images = train_images / 255.0

test_images = test_images / 255.0

# Setting up the layers.

model = keras.Sequential([

    keras.layers.Flatten(input_shape=(512, 512, 3)),
    
        keras.layers.Dense(128, activation=tf.nn.sigmoid),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(16, activation=tf.nn.sigmoid),
        keras.layers.Dropout(0.2),
    keras.layers.Dense(2, activation=tf.nn.softmax)

])

#Compile the model
sgd = keras.optimizers.SGD(learning_rate=0.01, decay=1e-5, momentum=0.7, nesterov=True)

model.compile(optimizer=sgd,

              loss='sparse_categorical_crossentropy',

              metrics=['accuracy'])

#Train the model and Accuracy test

nEpocas = []

for i in range(50, 75, 100, 150, 200, 250, 300, 350):
        model.fit(train_images, train_labels, epochs=i)
        nEpocas.append(i)
        valor = test_loss, test_acc = model.evaluate(test_images, test_labels)

results = dict.fromkeys(nEpocas , valor)

print('Test accuracy:', results)

#Prediction test
predictions = model.predict(test_images)

print(predictions)

display_images(test_images, np.argmax(predictions, axis = 1))

plt.show()

# salvar o modelo arquivo sale_xgboost.pkl
with open('/content/drive/MyDrive/TCC/Protótipo/TCC_model.pkl', 'wb') as file:
    pickle.dump(model, file)







"""#Importando Pacotes 
import pickle 
# Carregando a Máquina Preditiva
pickle_in = open('maquina_preditiva.pkl', 'rb') 
maquina_preditiva = pickle.load(pickle_in)

#Comando de Salvamento da Máquina Preditiva
import pickle 
pickle_out = open("maquina_preditiva.pkl", mode = "wb") 
pickle.dump(maquina, pickle_out) 
pickle_out.close()
"""